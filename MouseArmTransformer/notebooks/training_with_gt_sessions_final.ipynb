{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c8b50-7471-4e1d-ad4c-1c195d1c9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import pickle\n",
    "# From arm\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lifting_transformer.lifting_transformer import (\n",
    "    criterion,\n",
    "    data,\n",
    "    helper,\n",
    "    inference,\n",
    "    model,\n",
    "    training,\n",
    ")\n",
    "from mausspaun.data_processing.dlc import DLC_TO_MUJOCO_MAPPING\n",
    "from mausspaun.visualization.plot_3D_video import plot_split_3d_video\n",
    "\n",
    "#sys.path.append('../../../mouse-arm')\n",
    "#sys.path.append('../../../DataJoint_mathis')\n",
    "\n",
    "plt.style.use('cyhsm')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e90a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(path):\n",
    "    pattern = r\"mouse-(?P<mouse_name>\\w+)_day-(?P<day>\\d+)_attempt-(?P<attempt>\\d+)_camera-(?P<camera>\\d+)_part-(?P<part>\\d+)_\"\n",
    "    match = re.search(pattern, path)\n",
    "    if match:\n",
    "        return match.group(\"mouse_name\"), int(match.group(\"day\")), int(match.group(\"attempt\")), int(\n",
    "            match.group(\"camera\")), int(match.group(\"part\"))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def prep_ground_truth(full_session_names, gt_dataloader):\n",
    "    # Prep GT so that we can batch process all labeled frames at the same time\n",
    "    all_in, all_gt, count = [], [], 0\n",
    "    all_names = []\n",
    "    for idx, (session_name, (camera1, camera2, labels, gt_labels)) in enumerate(zip(full_session_names, gt_dataloader)):\n",
    "        if torch.nansum(~gt_labels.isnan()) == 0:\n",
    "            continue\n",
    "        # check for zeros\n",
    "        tmp_gt = gt_labels.detach().clone()\n",
    "        tmp_gt[tmp_gt == 0] = float('nan')\n",
    "        if torch.nansum(~tmp_gt.isnan()) == 0:\n",
    "            #print('Found zeros')\n",
    "            continue\n",
    "\n",
    "        #print(torch.nansum(gt_labels.isnan()))\n",
    "        if count == 0:\n",
    "            all_in = camera1\n",
    "            all_gt = gt_labels\n",
    "            all_names = [session_name]\n",
    "        else:\n",
    "            all_in = torch.concatenate((all_in, camera1), axis=0)\n",
    "            all_gt = torch.concatenate((all_gt, gt_labels), axis=0)\n",
    "            all_names = all_names + [session_name]\n",
    "        count += 1\n",
    "    print('Finished processing GT')\n",
    "    gt_dataloader.all_in = all_in\n",
    "    gt_dataloader.all_gt = all_gt\n",
    "    gt_dataloader.all_names = all_names\n",
    "    return gt_dataloader\n",
    "\n",
    "\n",
    "def save_video(epoch, test_preds, cam_positions, test_loss, cutoff, loss_weights, seq_length):\n",
    "    all_pred_positions = {key: test_preds[:, -1, i, :] for i, key in enumerate(cam_positions.keys())}\n",
    "    # if smoothing_window > 0:\n",
    "    #     for key, item in all_pred_positions.items():\n",
    "    #         all_pred_positions[key] = savgol_filter(item, smoothing_window, 3, axis=0)\n",
    "    info = {\n",
    "        \"epoch\":\n",
    "        epoch,\n",
    "        \"loss\":\n",
    "        test_loss,\n",
    "        \"seq_length\":\n",
    "        seq_length,\n",
    "        \"cutoff\":\n",
    "        cutoff,\n",
    "        \"loss_weights\":\n",
    "        str([\n",
    "            loss_weights['mse'], loss_weights['continuity'], loss_weights['connectivity'], loss_weights['ground_truth']\n",
    "        ])\n",
    "    }\n",
    "    run_name = \"{epoch}_loss{loss:.3f}_seq{seq_length}_cutoff{cutoff}_lossweights{loss_weights}\".format(**info)\n",
    "\n",
    "    labeled_2d_video = '/data/mausspaun/videos/videos_dlc2/rigVideo_mouse-Jaguar_day-19_attempt-1_camera-1_part-0_doe-20180813_rig-5.mp4'\n",
    "    #labeled_2d_video = '/data/markus/mausspaun/labeled_videos/rigVideo_mouse-HoneyBee_day-77_attempt-1_camera-1_part-6_doe-20180803_rig-5DLC_resnet50_MackenzieJan21shuffle1_700000.mp4'\n",
    "    plot_split_3d_video(\n",
    "        labeled_2d_video,\n",
    "        all_pred_positions,\n",
    "        cam_positions=cam_positions,\n",
    "        dpi=150,\n",
    "        frames=np.arange(0, 500),  #np.concatenate([np.arange(0, 50), np.arange(400, 450)]),\n",
    "        fn_save=\"/data/markus/mausspaun/3D/withcut0_{}\".format(run_name))\n",
    "\n",
    "\n",
    "def run_model(train_dataloader,\n",
    "              train_gt_dataloader,\n",
    "              test_dataloader,\n",
    "              test_gt_dataloader,\n",
    "              relative_displacements,\n",
    "              all_aggregated_tensor,\n",
    "              loss_weights=None,\n",
    "              num_epochs=25,\n",
    "              save_weights=False,\n",
    "              save_video_every=False,\n",
    "              seq_length=7):\n",
    "    # Get optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transformer = model.SimpleTransformer(num_joints=num_joints).to(device)\n",
    "    train_criterion = criterion.masked_loss_nan\n",
    "    eval_criterion = criterion.masked_loss_nan\n",
    "    optimizer = optim.Adam(transformer.parameters(), lr=0.0002)\n",
    "\n",
    "    # Train the model\n",
    "    if loss_weights is None:\n",
    "        loss_weights = {\n",
    "            \"mse\": 1,\n",
    "            \"continuity\": 25,\n",
    "            \"connectivity\": 1,\n",
    "            \"ground_truth\": 0.00001,\n",
    "        }\n",
    "    loss_weights_str = str(\n",
    "        [loss_weights['mse'], loss_weights['continuity'], loss_weights['connectivity'], loss_weights['ground_truth']])\n",
    "    losses, predictions = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = training.train(\n",
    "            transformer,\n",
    "            train_dataloader,\n",
    "            train_gt_dataloader,\n",
    "            device,\n",
    "            train_criterion,\n",
    "            optimizer,\n",
    "            loss_weights,\n",
    "            relative_displacements,\n",
    "            all_aggregated_tensor,\n",
    "        )\n",
    "        print(f\"Epoch {epoch+1} training loss: {train_loss:.5f}\")\n",
    "        test_loss, test_gt_loss, test_gt_loss_norel, test_preds, test_gt_preds = inference.evaluate(\n",
    "            transformer, test_dataloader, test_gt_dataloader, device, eval_criterion, relative_displacements)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1} test loss: {test_loss:.5f}, ground truth loss (sum): {torch.sum(test_gt_loss):.5f}, ground truth loss (mean): {torch.mean(test_gt_loss):.5f}, TS: {torch.mean(test_gt_loss[:,-1,...]):.5f}, ground truth loss (norel): {torch.mean(test_gt_loss_norel[:,-1,...]):.5f}\"\n",
    "        )\n",
    "\n",
    "        # Save losses\n",
    "        test_loss_norel = torch.mean(test_gt_loss_norel[:, -1, ...]).cpu().detach().numpy()\n",
    "        losses.append((train_loss, torch.mean(test_gt_loss[:, -1, ...]).cpu().detach().numpy(), test_loss_norel))\n",
    "        predictions.append((test_gt_preds, test_preds))\n",
    "\n",
    "        # Save video and weights\n",
    "        if save_video_every > 0:\n",
    "            if not ((epoch + 1) % save_video_every):\n",
    "                save_video(epoch, test_preds, cam_positions, test_loss, cutoff, loss_weights, seq_length)\n",
    "\n",
    "                if save_weights:\n",
    "                    torch.save(\n",
    "                        transformer.state_dict(),\n",
    "                        f\"/data/markus/mausspaun/3D/weights_withFixNewGT_{epoch}_loss{test_loss_norel}_seq{seq_length}_cutoff0.999_lossweights{loss_weights_str}.pt\"\n",
    "                    )\n",
    "\n",
    "    return np.array(losses), predictions\n",
    "\n",
    "\n",
    "def get_dataloaders(c1_train, c1_test, c2_train, c2_test, y_train, y_test, gt_train, gt_test, seq_length):\n",
    "    # Create train set\n",
    "    train_dataset = data.PositionDatasetGT(c1_train, c2_train, y_train, gt_train, seq_length=seq_length)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    train_gt_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Create test set\n",
    "    test_dataset = data.PositionDatasetGT(c1_test, c2_test, y_test, gt_test, seq_length=seq_length)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    test_gt_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Prep ground truth so we can batch process\n",
    "    train_gt_dataloader = prep_ground_truth(full_session_names, train_gt_dataloader)\n",
    "    test_gt_dataloader = prep_ground_truth(full_session_names, test_gt_dataloader)\n",
    "\n",
    "    return (train_dataset, train_dataloader, train_gt_dataloader), (test_dataset, test_dataloader, test_gt_dataloader)\n",
    "\n",
    "\n",
    "def get_groundtruth(reload=False):\n",
    "    save_path = '/data/markus/mausspaun/nn_training_data/ground_truth_data.pkl'\n",
    "    if os.path.exists(save_path) and not reload:\n",
    "        (full_gt, full_session_names, labeled_per_session, session_with_gt) = pickle.load(open(save_path, 'rb'))\n",
    "        return (full_gt, full_session_names, labeled_per_session, session_with_gt)\n",
    "\n",
    "    cam1_paths, cam2_paths = helper.get_paths()\n",
    "    session_with_gt, labeled_per_session = [], []\n",
    "    for idx, (cam1_path, cam2_path) in enumerate(zip(cam1_paths, cam2_paths)):\n",
    "        mouse_name, day, attempt, camera, part = extract_info(cam1_path)\n",
    "        gt = helper.load_and_process_ground_truth(mouse_name, day, attempt, part, to_mujoco=True)\n",
    "        print('Running: {}'.format(cam1_path))\n",
    "        try:\n",
    "            X_3d_train, X_2d_c1_train, X_2d_c2_train, cam_positions, likelihood_c1, likelihood_c2 = helper.get_training_data(\n",
    "                cam1_path, cam2_path, likelihood_cutoff=cutoff)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print('Could not load {}'.format(cam1_path))\n",
    "\n",
    "        X_gt = X_3d_train.copy() * np.NaN\n",
    "        if gt is not None:  # If not None then we have labeled 3D ground truth\n",
    "            for frame in gt['frame'].unique():\n",
    "                for marker in DLC_TO_MUJOCO_MAPPING.keys():\n",
    "                    if DLC_TO_MUJOCO_MAPPING[marker] not in helper.mausspaun_keys:\n",
    "                        continue\n",
    "                    marker_index = helper.mausspaun_keys.index(DLC_TO_MUJOCO_MAPPING[marker])\n",
    "                    gt_values = gt[(gt['frame'] == frame) & (gt['bodypart'] == marker)][['x', 'y', 'z']].values\n",
    "                    X_gt[frame, marker_index, :] = gt_values\n",
    "\n",
    "        labeled_frames = np.nansum(X_gt, axis=(1, 2)) != 0\n",
    "        num_labeled = np.sum(labeled_frames)\n",
    "        print(f\"Found {num_labeled} frames\")\n",
    "\n",
    "        session_name = {'mouse_name': mouse_name, 'day': day, 'attempt': attempt, 'camera': camera, 'part': part}\n",
    "        #f\"{mouse_name}-day{day}-attempt{attempt}-camera{camera}-part{part}\"\n",
    "        session_names = [session_name] * X_gt.shape[0]\n",
    "        if idx == 0:\n",
    "            full_gt = X_gt\n",
    "            full_session_names = session_names\n",
    "        else:\n",
    "            full_gt = np.vstack((full_gt, X_gt))\n",
    "            full_session_names = full_session_names + session_names\n",
    "        if not (np.nansum(X_gt) == 0.0):\n",
    "            session_with_gt.append(session_names[0])\n",
    "            labeled_per_session.append(num_labeled)\n",
    "    pickle.dump((full_gt, full_session_names, labeled_per_session, session_with_gt), open(save_path, 'wb'))\n",
    "    return (full_gt, full_session_names, labeled_per_session, session_with_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931abf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess data for model training\n",
    "cutoff = 0.0\n",
    "full_X_c1, full_X_c2, full_y = helper.load_data(\n",
    "    reload=False, path='/data/markus/mausspaun/nn_training_data/data_with_left_{}.pkl'.format(cutoff), cutoff=cutoff)\n",
    "print('X Camera 1: {}, X Camera 2: {}, Y: {}'.format(full_X_c1.shape, full_X_c2.shape, full_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e0ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16cfc1a9",
   "metadata": {},
   "source": [
    "---\n",
    "# Get groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46819bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(full_gt, full_session_names, labeled_per_session, session_with_gt) = get_groundtruth(reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 13\n",
    "num_joints = 32\n",
    "\n",
    "# Get relative displacements\n",
    "(_, _, _, cam_positions, likelihood_c1, likelihood_c2) = helper.load_test_data()\n",
    "all_aggregated_tensor, relative_displacements = helper.get_relative_displacements(cam_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#session_with_gt = [{'mouse_name': 'HoneyBee', 'day': 77, 'attempt': 1, 'camera': 1, 'part': 6}]\n",
    "#session_with_gt = [{'mouse_name': 'HoneyBee', 'day': 77, 'attempt': 1, 'camera': 1, 'part': 0}]\n",
    "session_with_gt = [{'mouse_name': 'Jaguar', 'day': 19, 'attempt': 1, 'camera': 1, 'part': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = {\"mse\": 1, \"continuity\": 25, \"connectivity\": 1, \"ground_truth\": 1}\n",
    "gt_weights = [0.0001]  #[0.0001] #[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "num_epochs = 10\n",
    "use_full_training = False\n",
    "\n",
    "losses = []\n",
    "for gt in gt_weights:\n",
    "    loss_weights[\"ground_truth\"] = gt\n",
    "    print(loss_weights)\n",
    "\n",
    "    cv_losses = []\n",
    "    for cv_fold, session in enumerate(session_with_gt):\n",
    "        test_index = [i for i, x in enumerate(full_session_names) if x == session]\n",
    "        train_index = [i for i, x in enumerate(full_session_names) if x != session]\n",
    "\n",
    "        # Splitting the data for this fold\n",
    "        c1_train, c1_test = full_X_c1[train_index], full_X_c1[test_index]\n",
    "        c2_train, c2_test = full_X_c2[train_index], full_X_c2[test_index]\n",
    "        y_train, y_test = full_y[train_index], full_y[test_index]\n",
    "        gt_train, gt_test = full_gt[train_index], full_gt[test_index]\n",
    "\n",
    "        print('Size of training: {}, Size of Test: {}'.format(y_train.shape, y_test.shape))\n",
    "\n",
    "        # Ensure test set has ground truth data\n",
    "        # assert np.nansum(gt_test) != 0, f\"No GT in test set for fold {fold}\"\n",
    "        #         if np.nansum(gt_test) == 0:\n",
    "        #             print('No test data in fold: {}'.format(cv_fold))\n",
    "        #             continue\n",
    "\n",
    "        if use_full_training:\n",
    "            (train_dataset, train_dataloader,\n",
    "             train_gt_dataloader), (test_dataset, test_dataloader,\n",
    "                                    test_gt_dataloader) = get_dataloaders(full_X_c1, c1_test, full_X_c2, c2_test,\n",
    "                                                                          full_y, y_test, full_gt, gt_test, seq_length)\n",
    "        else:\n",
    "            (train_dataset, train_dataloader,\n",
    "             train_gt_dataloader), (test_dataset, test_dataloader,\n",
    "                                    test_gt_dataloader) = get_dataloaders(c1_train, c1_test, c2_train, c2_test, y_train,\n",
    "                                                                          y_test, gt_train, gt_test, seq_length)\n",
    "\n",
    "        model_losses, predictions = run_model(train_dataloader,\n",
    "                                              train_gt_dataloader,\n",
    "                                              test_dataloader,\n",
    "                                              test_gt_dataloader,\n",
    "                                              relative_displacements,\n",
    "                                              all_aggregated_tensor,\n",
    "                                              loss_weights,\n",
    "                                              save_weights=True,\n",
    "                                              seq_length=seq_length,\n",
    "                                              num_epochs=num_epochs,\n",
    "                                              save_video_every=3)\n",
    "        cv_losses.append(model_losses)\n",
    "    losses.append(cv_losses)\n",
    "losses = np.array(losses)\n",
    "pickle.dump((gt_weights, losses, labeled_per_session, session_with_gt),\n",
    "            open('./losses_full_cut0_cv_to{}_sessions{}.p'.format(num_epochs, len(session_with_gt)), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd02db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff737a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e5fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gt_weights, losses, labeled_per_session,\n",
    " session_with_gt) = pickle.load(open('./losses_full2_cv_to50_sessions1.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f442a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f904e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plotting Train and Test Sum in the first subplot\n",
    "parameters = gt_weights\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(parameters) + 1))\n",
    "for i, (color, param) in enumerate(zip(colors, parameters)):\n",
    "    means = np.mean(losses[i, :, :, 2], axis=0)  # Test Mean\n",
    "    stds = np.std(losses[i, :, :, 2], axis=0)\n",
    "    axes[1].errorbar(epochs, means, yerr=stds / 100, label=f\"Param {param}\", color=color, capsize=4)\n",
    "\n",
    "for i, (color, param) in enumerate(zip(colors, parameters)):\n",
    "    means = np.mean(losses[i, :, :, 1], axis=0)  # Test Mean\n",
    "    stds = np.std(losses[i, :, :, 1], axis=0)\n",
    "    axes[0].errorbar(epochs, means, yerr=stds / 100, label=f\"Param {param}\", color=color, capsize=4)\n",
    "\n",
    "best_weight = np.argmin(np.mean(losses, axis=(1, 2, 3)))\n",
    "print('Best Weight: {}'.format(gt_weights[best_weight]))\n",
    "\n",
    "legend_labels = [\n",
    "    f\"{sgt['mouse_name']}-Day{sgt['day']} | #Labeled: {labeled}\"\n",
    "    for sgt, labeled in zip(session_with_gt, labeled_per_session)\n",
    "]\n",
    "axes[2].plot(losses[best_weight, :, :, 1].T)\n",
    "axes[2].legend(legend_labels, fontsize=7)\n",
    "axes[3].plot(losses[best_weight, :, :, 2].T)\n",
    "#axes[3].legend(legend_labels, fontsize=7)\n",
    "\n",
    "# Setting titles, labels and legends\n",
    "axes[0].set_title(\"Test Last Timestep\")\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "axes[1].set_title(\"Test Last Timestep No Rel. Displacement\")\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9740e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
